{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lxmert+lstmcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Hgy15-l_hD",
        "outputId": "73e1ce8a-8aae-4168-d637-d5986f16a8e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEqS8vSqmAEW"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/lxmert-scripts\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iUhiyFVvf8U"
      },
      "source": [
        "import json\n",
        "with open('data/vqa/classifier_ans2label.json') as f_a2l:\n",
        "  ans2label = json.load(f_a2l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OauLG7rQvjvN",
        "outputId": "f2e8ab23-593f-4ea1-fef5-1fe907442420"
      },
      "source": [
        "print(ans2label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'binary': 0, 'number': 1, 'unanswerable': 2, 'other': 3, 'color': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEjFEH7FvlM5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7QS1lW7vnlI"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfZBapZIfUR6"
      },
      "source": [
        "#use small data to test, make sure no error\n",
        "!bash run/vqa_finetune_v2.bash 0 vizwiz_just_a_test --tiny"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WLZI07cv-P1",
        "outputId": "e0368df2-4593-4805-c2e9-b99c66b7291c"
      },
      "source": [
        "!bash run/vqa_finetune_v2.bash 0 vizwiz_lstmcnn_lxmert_fuse_before"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 06:45:07.861245: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "train\n",
            "Load 20523 data from split(s) train.\n",
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_train.pkl\n",
            "Loaded 23948 images in file data/vizwiz_imgfeat/36_vizwiz_train.pkl in 78 seconds.\n",
            "Use 20518 data in torch dataset\n",
            "\n",
            "valid\n",
            "Load 4319 data from split(s) valid.\n",
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_val.pkl\n",
            "Loaded 7748 images in file data/vizwiz_imgfeat/36_vizwiz_val.pkl in 25 seconds.\n",
            "Use 4317 data in torch dataset\n",
            "\n",
            "LXRT encoder with 9 l_layers, 5 x_layers, and 5 r_layers.\n",
            "Load QA pre-trained LXMERT from snap/pretrained/model \n",
            "Loaded 2858 answers from LXRTQA pre-training and 45872 not\n",
            "\n",
            "Loading Model from /content/drive/MyDrive/lxmert/lstmcnn_classifier/best_accuracy_log.pth\n",
            "classifier loaded from checkpoint\n",
            "BertAdam Total Iters: 19230\n",
            "Splits in Train data: ['train']\n",
            "Splits in Valid data: ['valid']\n",
            "tcmalloc: large alloc 1644167168 bytes == 0x55ed57946000 @  0x7fa552729b6b 0x7fa552749379 0x7fa4e016825e 0x7fa4e01699d2 0x7fa51da30853 0x7fa51d2349cf 0x7fa51d9e248a 0x7fa51d2d3c31 0x7fa51d2d4425 0x7fa51d7bc735 0x7fa51d731031 0x7fa51d5b7955 0x7fa51d2d5e67 0x7fa51d879048 0x7fa51d8790c8 0x7fa51d731031 0x7fa51d5b73b5 0x7fa51d2cd41c 0x7fa51d8802c8 0x7fa51d880348 0x7fa51d731031 0x7fa51d5b7595 0x7fa51eec0905 0x7fa51eec10d8 0x7fa51d731031 0x7fa51d5b7595 0x7fa52e9f5693 0x55e9dd700d54 0x55e9dd700a50 0x55e9dd775105 0x55e9dd76f7ad\n",
            "0\n",
            "tcmalloc: large alloc 1644167168 bytes == 0x55ed57946000 @  0x7fa552729b6b 0x7fa552749379 0x7fa4e016825e 0x7fa4e01699d2 0x7fa51da30853 0x7fa51d2349cf 0x7fa51d9e248a 0x7fa51d2d3c31 0x7fa51d2d4425 0x7fa51d7bc735 0x7fa51d731031 0x7fa51d5b7955 0x7fa51d2d5e67 0x7fa51d879048 0x7fa51d8790c8 0x7fa51d731031 0x7fa51d5b73b5 0x7fa51d2cd41c 0x7fa51d8802c8 0x7fa51d880348 0x7fa51d731031 0x7fa51d5b7595 0x7fa51eec0905 0x7fa51eec10d8 0x7fa51d731031 0x7fa51d5b7595 0x7fa52e9f5693 0x55e9dd700d54 0x55e9dd700a50 0x55e9dd775105 0x55e9dd76f7ad\n",
            "1\n",
            "tcmalloc: large alloc 1644167168 bytes == 0x55ed5735a000 @  0x7fa552729b6b 0x7fa552749379 0x7fa4e016825e 0x7fa4e01699d2 0x7fa51da30853 0x7fa51d2349cf 0x7fa51d9e248a 0x7fa51d2d3c31 0x7fa51d2d4425 0x7fa51d7bc735 0x7fa51d731031 0x7fa51d5b7955 0x7fa51d2d5e67 0x7fa51d879048 0x7fa51d8790c8 0x7fa51d731031 0x7fa51d5b73b5 0x7fa51d2cd41c 0x7fa51d8802c8 0x7fa51d880348 0x7fa51d731031 0x7fa51d5b7595 0x7fa51eec0905 0x7fa51eec10d8 0x7fa51d731031 0x7fa51d5b7595 0x7fa52e9f5693 0x55e9dd700d54 0x55e9dd700a50 0x55e9dd775105 0x55e9dd76f7ad\n",
            "2\n",
            "tcmalloc: large alloc 1644167168 bytes == 0x55ed5735a000 @  0x7fa552729b6b 0x7fa552749379 0x7fa4e016825e 0x7fa4e01699d2 0x7fa51da30853 0x7fa51d2349cf 0x7fa51d9e248a 0x7fa51d2d3c31 0x7fa51d2d4425 0x7fa51d7bc735 0x7fa51d731031 0x7fa51d5b7955 0x7fa51d2d5e67 0x7fa51d879048 0x7fa51d8790c8 0x7fa51d731031 0x7fa51d5b73b5 0x7fa51d2cd41c 0x7fa51d8802c8 0x7fa51d880348 0x7fa51d731031 0x7fa51d5b7595 0x7fa51eec0905 0x7fa51eec10d8 0x7fa51d731031 0x7fa51d5b7595 0x7fa52e9f5693 0x55e9dd700d54 0x55e9dd700a50 0x55e9dd775105 0x55e9dd76f7ad\n",
            "3\n",
            "4\n",
            "Valid Oracle: 92.71\n",
            "start train\n",
            "  0% 0/641 [00:00<?, ?it/s]/content/drive/.shortcut-targets-by-id/1XQxxii5VRN3kehCSLx8F8y2nADjT1S4d/lxmert/src/lxrt/optimization.py:142: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "100% 641/641 [08:20<00:00,  1.28it/s]\n",
            "\n",
            "Epoch 0: Train 22.99\n",
            "Epoch 0: Valid 36.41\n",
            "Epoch 0: Best 36.41\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 1: Train 35.39\n",
            "Epoch 1: Valid 38.96\n",
            "Epoch 1: Best 38.96\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 2: Train 41.17\n",
            "Epoch 2: Valid 41.28\n",
            "Epoch 2: Best 41.28\n",
            "100% 641/641 [07:49<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 3: Train 45.39\n",
            "Epoch 3: Valid 41.95\n",
            "Epoch 3: Best 41.95\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 4: Train 50.50\n",
            "Epoch 4: Valid 43.75\n",
            "Epoch 4: Best 43.75\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 5: Train 55.40\n",
            "Epoch 5: Valid 44.45\n",
            "Epoch 5: Best 44.45\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 6: Train 60.46\n",
            "Epoch 6: Valid 44.32\n",
            "Epoch 6: Best 44.45\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 7: Train 65.13\n",
            "Epoch 7: Valid 45.75\n",
            "Epoch 7: Best 45.75\n",
            "100% 641/641 [07:51<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 8: Train 69.45\n",
            "Epoch 8: Valid 45.95\n",
            "Epoch 8: Best 45.95\n",
            "100% 641/641 [07:50<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 9: Train 74.12\n",
            "Epoch 9: Valid 46.26\n",
            "Epoch 9: Best 46.26\n",
            "100% 641/641 [07:49<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 10: Train 78.78\n",
            "Epoch 10: Valid 45.03\n",
            "Epoch 10: Best 46.26\n",
            "100% 641/641 [07:48<00:00,  1.37it/s]\n",
            "\n",
            "Epoch 11: Train 82.94\n",
            "Epoch 11: Valid 46.38\n",
            "Epoch 11: Best 46.38\n",
            "100% 641/641 [07:50<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 12: Train 86.14\n",
            "Epoch 12: Valid 47.21\n",
            "Epoch 12: Best 47.21\n",
            "100% 641/641 [07:50<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 13: Train 88.08\n",
            "Epoch 13: Valid 46.59\n",
            "Epoch 13: Best 47.21\n",
            "100% 641/641 [07:51<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 14: Train 89.23\n",
            "Epoch 14: Valid 45.67\n",
            "Epoch 14: Best 47.21\n",
            "100% 641/641 [07:52<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 15: Train 90.07\n",
            "Epoch 15: Valid 47.06\n",
            "Epoch 15: Best 47.21\n",
            "100% 641/641 [07:52<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 16: Train 90.69\n",
            "Epoch 16: Valid 47.22\n",
            "Epoch 16: Best 47.22\n",
            "100% 641/641 [07:54<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 17: Train 91.17\n",
            "Epoch 17: Valid 47.74\n",
            "Epoch 17: Best 47.74\n",
            "100% 641/641 [07:54<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 18: Train 91.44\n",
            "Epoch 18: Valid 46.67\n",
            "Epoch 18: Best 47.74\n",
            "100% 641/641 [07:52<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 19: Train 91.64\n",
            "Epoch 19: Valid 46.86\n",
            "Epoch 19: Best 47.74\n",
            "100% 641/641 [07:51<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 20: Train 91.91\n",
            "Epoch 20: Valid 46.91\n",
            "Epoch 20: Best 47.74\n",
            "100% 641/641 [07:50<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 21: Train 92.04\n",
            "Epoch 21: Valid 47.93\n",
            "Epoch 21: Best 47.93\n",
            "100% 641/641 [07:52<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 22: Train 92.23\n",
            "Epoch 22: Valid 47.41\n",
            "Epoch 22: Best 47.93\n",
            "100% 641/641 [07:50<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 23: Train 92.35\n",
            "Epoch 23: Valid 47.35\n",
            "Epoch 23: Best 47.93\n",
            "100% 641/641 [07:53<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 24: Train 92.53\n",
            "Epoch 24: Valid 47.36\n",
            "Epoch 24: Best 47.93\n",
            "100% 641/641 [07:54<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 25: Train 92.61\n",
            "Epoch 25: Valid 47.53\n",
            "Epoch 25: Best 47.93\n",
            "100% 641/641 [07:54<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 26: Train 92.71\n",
            "Epoch 26: Valid 47.35\n",
            "Epoch 26: Best 47.93\n",
            "100% 641/641 [07:53<00:00,  1.35it/s]\n",
            "\n",
            "Epoch 27: Train 92.79\n",
            "Epoch 27: Valid 47.52\n",
            "Epoch 27: Best 47.93\n",
            "100% 641/641 [07:51<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 28: Train 92.83\n",
            "Epoch 28: Valid 47.53\n",
            "Epoch 28: Best 47.93\n",
            "100% 641/641 [07:52<00:00,  1.36it/s]\n",
            "\n",
            "Epoch 29: Train 92.89\n",
            "Epoch 29: Valid 47.58\n",
            "Epoch 29: Best 47.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMbMCWs5wHWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e83ff36-6db2-491c-f791-7742bba9c378"
      },
      "source": [
        "!bash run/vqa_test_v2.bash 0 vizwiz_lstmcnn_lxmert_fuse_before --test valid --load snap/vqa/vizwiz_lstmcnn_lxmert_fuse_before/BEST"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-15 20:18:58.385573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "train\n",
            "Load 20523 data from split(s) train.\n",
            "Start to load Faster-RCNN detected objects from data/vizwiz_imgfeat/36_vizwiz_train.pkl\n",
            "Traceback (most recent call last):\n",
            "  File \"src/tasks/vqa_combine_v2.py\", line 328, in <module>\n",
            "    vqa = VQA(config)\n",
            "  File \"src/tasks/vqa_combine_v2.py\", line 59, in __init__\n",
            "    args.train, bs=args.batch_size, shuffle=True, drop_last=True, config=config,\n",
            "  File \"src/tasks/vqa_combine_v2.py\", line 44, in get_data_tuple\n",
            "    tset = VQATorchDataset(dset)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1KGjAEAJ0J6dMkVzEcRNa2jEyeUcqNUNJ/lxmert-scripts/src/tasks/vqa_data_v2.py\", line 184, in __init__\n",
            "    topk=load_topk))\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1KGjAEAJ0J6dMkVzEcRNa2jEyeUcqNUNJ/lxmert-scripts/src/utils.py\", line 64, in load_obj_pkl\n",
            "    with open(fname, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/vizwiz_imgfeat/36_vizwiz_train.pkl'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m_TbT3FtERq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}